{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stylegan2-ADA",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMZlFqe+F18AqLtlJJPvR0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericstheguy/Stylegan2-ADA-Colab/blob/main/Stylegan2_ADA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMSzDN4wjNk-"
      },
      "source": [
        "#***Stylegan2-ADA Latent Space***\n",
        "###Change Runtime to GPU, and when starting run top to bottom."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OzNhauPwxej"
      },
      "source": [
        "*(In simplified terms, this colab notebook is an easy way to see how a state-of-the-art AI recreates a picture from many other pictures.)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vkMefwcjrPo",
        "outputId": "5825823d-8430-46d8-9222-1fa2c67841fe"
      },
      "source": [
        "#@title Installation { form-width: \"20px\" }\n",
        "%tensorflow_version 1.x\n",
        "import os \n",
        "from google.colab import files\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada\n",
        "%cd /content/stylegan2-ada/\n",
        "!mkdir Output\n",
        "!mkdir Input\n",
        "out = \"/content/stylegan2-ada/Output\" \n",
        "target = \"/content/stylegan2-ada/Input\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Total 71 (delta 0), reused 0 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n",
            "/content/stylegan2-ada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ6JhMzzubOf"
      },
      "source": [
        "Before Uploading: Upload a 1:1 (square size.) cropped PNG image front on with the name Image.png . (Link for example: https://github.com/NVlabs/ffhq-dataset. Search online for examples that include images of other models.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "Z1m2mWlwnfP7",
        "outputId": "6c4a3222-b300-4345-c5cf-7b22b022cf3f"
      },
      "source": [
        "#@title Upload an Image { form-width: \"20px\" }\n",
        "%cd /content/stylegan2-ada/Input\n",
        "#files.upload()\n",
        "%cd /content/stylegan2-ada/Input\n",
        "%cd /content/stylegan2-ada"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-14bfaa6aa96b>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    get_ipython().system('print filename')\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "0XkcUsFIjn6b",
        "outputId": "1dcecb04-024c-4fb0-be94-4876406e98f3"
      },
      "source": [
        "#@title Choose Model and Run.\n",
        "Model = \"ffhq\" #@param [\"ffhq\", \"afhqdog\", \"afhqcat\", \"afhqwild\", \"metfaces\"]\n",
        "\n",
        "!python projector.py --outdir={out} --target={target} \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/{Model}.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-25 05:22:25.478238: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\"...\n",
            "Traceback (most recent call last):\n",
            "  File \"projector.py\", line 287, in <module>\n",
            "    main()\n",
            "  File \"projector.py\", line 282, in main\n",
            "    project(**vars(parser.parse_args()))\n",
            "  File \"projector.py\", line 213, in project\n",
            "    target_pil = PIL.Image.open(target_fname)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 2809, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "IsADirectoryError: [Errno 21] Is a directory: '/content/Input/'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u9oGbCFtA_V"
      },
      "source": [
        "## **Model Guide:**\n",
        "ffhq = Human faces <p> afhqdog = Dogs <p> afhqcat = Cats <p> afhqwild = Other animals <p> metfaces = Old portrait paintings. <p>\n",
        "### All create, partially front facing images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "cellView": "form",
        "id": "AlxUqgsJnoiR",
        "outputId": "a8e8989e-6b46-4a5a-9680-ed987221837a"
      },
      "source": [
        "#@title Download Image and Video. { form-width: \"20px\" }\n",
        "os.rename(r'/content/stylegan2-ada/Output/proj.mp4',r'/content/stylegan2-ada/Output/InterpolatedVideo.mp4')\n",
        "os.rename(r'/content/stylegan2-ada/Output/proj.png',r'/content/stylegan2-ada/Output/LatentImage.png')\n",
        "!rm /content/stylegan2-ada/Input/\n",
        "files.download(\"/content/stylegan2-ada/Output/InterpolatedVideo.mp4,LatentImage.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-89a6f5af1706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/stylegan2-ada/Output/proj.mp4'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mr'/content/stylegan2-ada/Output/InterpolatedVideo.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/stylegan2-ada/Output/proj.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mr'/content/stylegan2-ada/Output/LatentImage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm /content/stylegan2-ada/Input/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/stylegan2-ada/Output/proj.mp4,proj.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/stylegan2-ada/Output/proj.mp4' -> '/content/stylegan2-ada/Output/InterpolatedVideo.mp4'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1DFNobuyj9n"
      },
      "source": [
        "###**End.** (To redo another image, go back to *Upload an Image*)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KnyXryb8xkQ-"
      },
      "source": [
        "#@title â€Ž\n",
        "#yes this whole notebook is coded horribly. I barely have any coding experience and just wanted to make a thoroughly documented way for really just running one command. \n",
        "#also I don't have the knowledge or the tolerance to put in some ffhq face aligner, Have no clue how to start."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}